{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import os\n",
    "os.chdir(\"D:\\\\\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Readind data and making a frame\n",
    "exoTrain=pd.read_csv(\"exoTrain.csv\")\n",
    "exoTest=pd.read_csv(\"exoTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoTrain.head()\n",
    "exoTest.head()\n",
    "df=np.concatenate([exoTrain,exoTest],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5087, 3198)\n",
      "(570, 3198)\n"
     ]
    }
   ],
   "source": [
    "print(exoTrain.shape)\n",
    "print(exoTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging dataframe\n",
    "df=pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=['Label']\n",
    "for i in range(3197):\n",
    "    x=(\"flux_\"+str(i))\n",
    "    list.append(x)\n",
    "#print(list)\n",
    "df.columns=list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>flux_0</th>\n",
       "      <th>flux_1</th>\n",
       "      <th>flux_2</th>\n",
       "      <th>flux_3</th>\n",
       "      <th>flux_4</th>\n",
       "      <th>flux_5</th>\n",
       "      <th>flux_6</th>\n",
       "      <th>flux_7</th>\n",
       "      <th>flux_8</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_3187</th>\n",
       "      <th>flux_3188</th>\n",
       "      <th>flux_3189</th>\n",
       "      <th>flux_3190</th>\n",
       "      <th>flux_3191</th>\n",
       "      <th>flux_3192</th>\n",
       "      <th>flux_3193</th>\n",
       "      <th>flux_3194</th>\n",
       "      <th>flux_3195</th>\n",
       "      <th>flux_3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label   flux_0   flux_1   flux_2   flux_3   flux_4   flux_5  flux_6  \\\n",
       "0    2.0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1    2.0   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2    2.0   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3    2.0   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4    2.0 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    flux_7  flux_8  ...  flux_3187  flux_3188  flux_3189  flux_3190  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   flux_3191  flux_3192  flux_3193  flux_3194  flux_3195  flux_3196  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completing the DataFrame\n",
    "df['Label'].unique()\n",
    "df['Label'].replace([1.0],'0',inplace=True)\n",
    "df['Label'].replace([2.0],'1',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of Index(['Label', 'flux_0', 'flux_1', 'flux_2', 'flux_3', 'flux_4', 'flux_5',\n",
       "       'flux_6', 'flux_7', 'flux_8',\n",
       "       ...\n",
       "       'flux_3187', 'flux_3188', 'flux_3189', 'flux_3190', 'flux_3191',\n",
       "       'flux_3192', 'flux_3193', 'flux_3194', 'flux_3195', 'flux_3196'],\n",
       "      dtype='object', length=3198)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label'].value_counts()\n",
    "#########################################################################\n",
    "df.columns.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1aad54bb780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the scatter plot for checking correlation\n",
    "x=df['flux_3187']\n",
    "y=df['flux_3192']\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>flux_0</th>\n",
       "      <th>flux_1</th>\n",
       "      <th>flux_2</th>\n",
       "      <th>flux_3</th>\n",
       "      <th>flux_4</th>\n",
       "      <th>flux_5</th>\n",
       "      <th>flux_6</th>\n",
       "      <th>flux_7</th>\n",
       "      <th>flux_8</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_3187</th>\n",
       "      <th>flux_3188</th>\n",
       "      <th>flux_3189</th>\n",
       "      <th>flux_3190</th>\n",
       "      <th>flux_3191</th>\n",
       "      <th>flux_3192</th>\n",
       "      <th>flux_3193</th>\n",
       "      <th>flux_3194</th>\n",
       "      <th>flux_3195</th>\n",
       "      <th>flux_3196</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label   flux_0   flux_1   flux_2   flux_3   flux_4   flux_5  flux_6  \\\n",
       "0     1    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1     1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2     1   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3     1   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4     1 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    flux_7  flux_8  ...  flux_3187  flux_3188  flux_3189  flux_3190  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   flux_3191  flux_3192  flux_3193  flux_3194  flux_3195  flux_3196  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label\n",
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating the dataset for the importance variable\n",
    "X_train=df.iloc[:,1:]\n",
    "y_train=df.iloc[:,0:1]\n",
    "X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['flux_0', 'flux_1', 'flux_2', 'flux_3', 'flux_4', 'flux_5', 'flux_6',\n",
       "       'flux_7', 'flux_8', 'flux_9',\n",
       "       ...\n",
       "       'flux_3187', 'flux_3188', 'flux_3189', 'flux_3190', 'flux_3191',\n",
       "       'flux_3192', 'flux_3193', 'flux_3194', 'flux_3195', 'flux_3196'],\n",
       "      dtype='object', length=3197)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeking Variable importance with rf and gini index\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flux_2383    0.001907\n",
       "flux_2587    0.001458\n",
       "flux_2347    0.001367\n",
       "flux_1098    0.001357\n",
       "flux_2348    0.001218\n",
       "flux_2346    0.001209\n",
       "flux_2651    0.001186\n",
       "flux_2382    0.001182\n",
       "flux_3011    0.001134\n",
       "flux_1730    0.001118\n",
       "flux_1280    0.001003\n",
       "flux_177     0.000997\n",
       "flux_724     0.000996\n",
       "flux_429     0.000988\n",
       "flux_3132    0.000960\n",
       "flux_1951    0.000951\n",
       "flux_1744    0.000950\n",
       "flux_1504    0.000950\n",
       "flux_3031    0.000946\n",
       "flux_1966    0.000933\n",
       "flux_1816    0.000927\n",
       "flux_490     0.000924\n",
       "flux_2288    0.000920\n",
       "flux_1054    0.000918\n",
       "flux_2754    0.000914\n",
       "flux_2349    0.000905\n",
       "flux_1995    0.000903\n",
       "flux_2419    0.000901\n",
       "flux_3176    0.000897\n",
       "flux_2247    0.000886\n",
       "               ...   \n",
       "flux_2893    0.000013\n",
       "flux_3179    0.000010\n",
       "flux_915     0.000009\n",
       "flux_615     0.000009\n",
       "flux_541     0.000009\n",
       "flux_1792    0.000009\n",
       "flux_1543    0.000008\n",
       "flux_277     0.000008\n",
       "flux_1379    0.000006\n",
       "flux_1998    0.000006\n",
       "flux_2779    0.000004\n",
       "flux_2948    0.000004\n",
       "flux_3080    0.000004\n",
       "flux_1600    0.000002\n",
       "flux_1585    0.000002\n",
       "flux_55      0.000001\n",
       "flux_332     0.000000\n",
       "flux_2977    0.000000\n",
       "flux_237     0.000000\n",
       "flux_1076    0.000000\n",
       "flux_407     0.000000\n",
       "flux_1239    0.000000\n",
       "flux_1961    0.000000\n",
       "flux_1752    0.000000\n",
       "flux_806     0.000000\n",
       "flux_827     0.000000\n",
       "flux_2355    0.000000\n",
       "flux_1525    0.000000\n",
       "flux_1124    0.000000\n",
       "flux_796     0.000000\n",
       "Length: 3197, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp=pd.Series(clf.feature_importances_,index=df.columns[1:]).sort_values(ascending=False)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp continue\n",
    "gini_fetures=feature_imp[feature_imp > 0.0004]\n",
    "gini_fet=gini_fetures.index\n",
    "df_gini=df.loc[:,gini_fet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 905)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_gini.head()\n",
    "df_gini.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 906)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reconstructing the dataframe after gini index\n",
    "df_g=pd.concat([y_train,df_gini],axis=1)\n",
    "df_g=pd.DataFrame(df_g)\n",
    "df_g.head()\n",
    "df_g.shape\n",
    "# Got DataFrame as per the requiremen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flux_2383</th>\n",
       "      <th>flux_2587</th>\n",
       "      <th>flux_2347</th>\n",
       "      <th>flux_1098</th>\n",
       "      <th>flux_2348</th>\n",
       "      <th>flux_2346</th>\n",
       "      <th>flux_2651</th>\n",
       "      <th>flux_2382</th>\n",
       "      <th>flux_3011</th>\n",
       "      <th>flux_1730</th>\n",
       "      <th>...</th>\n",
       "      <th>flux_2464</th>\n",
       "      <th>flux_1723</th>\n",
       "      <th>flux_278</th>\n",
       "      <th>flux_1447</th>\n",
       "      <th>flux_2513</th>\n",
       "      <th>flux_1946</th>\n",
       "      <th>flux_111</th>\n",
       "      <th>flux_1089</th>\n",
       "      <th>flux_1983</th>\n",
       "      <th>flux_3064</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-341.53</td>\n",
       "      <td>198.00</td>\n",
       "      <td>-313.67</td>\n",
       "      <td>111.88</td>\n",
       "      <td>144.41</td>\n",
       "      <td>-347.23</td>\n",
       "      <td>235.23</td>\n",
       "      <td>-291.13</td>\n",
       "      <td>182.29</td>\n",
       "      <td>-18.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-239.54</td>\n",
       "      <td>-32.81</td>\n",
       "      <td>-25.92</td>\n",
       "      <td>-161.26</td>\n",
       "      <td>-176.41</td>\n",
       "      <td>308.42</td>\n",
       "      <td>56.37</td>\n",
       "      <td>126.75</td>\n",
       "      <td>182.44</td>\n",
       "      <td>-50.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-144.77</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-159.10</td>\n",
       "      <td>-49.89</td>\n",
       "      <td>1.61</td>\n",
       "      <td>-159.68</td>\n",
       "      <td>60.24</td>\n",
       "      <td>-144.77</td>\n",
       "      <td>42.68</td>\n",
       "      <td>18.82</td>\n",
       "      <td>...</td>\n",
       "      <td>-235.52</td>\n",
       "      <td>50.60</td>\n",
       "      <td>107.03</td>\n",
       "      <td>0.79</td>\n",
       "      <td>-57.55</td>\n",
       "      <td>31.20</td>\n",
       "      <td>20.44</td>\n",
       "      <td>-41.71</td>\n",
       "      <td>-269.89</td>\n",
       "      <td>39.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-236.69</td>\n",
       "      <td>246.61</td>\n",
       "      <td>-209.41</td>\n",
       "      <td>-40.55</td>\n",
       "      <td>-874.95</td>\n",
       "      <td>-183.11</td>\n",
       "      <td>-52.27</td>\n",
       "      <td>-171.53</td>\n",
       "      <td>-176.77</td>\n",
       "      <td>345.05</td>\n",
       "      <td>...</td>\n",
       "      <td>-313.84</td>\n",
       "      <td>446.11</td>\n",
       "      <td>-693.73</td>\n",
       "      <td>-156.77</td>\n",
       "      <td>0.56</td>\n",
       "      <td>281.91</td>\n",
       "      <td>105.19</td>\n",
       "      <td>107.98</td>\n",
       "      <td>111.78</td>\n",
       "      <td>-114.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.84</td>\n",
       "      <td>-178.44</td>\n",
       "      <td>106.78</td>\n",
       "      <td>124.63</td>\n",
       "      <td>224.95</td>\n",
       "      <td>120.21</td>\n",
       "      <td>-140.66</td>\n",
       "      <td>121.77</td>\n",
       "      <td>105.35</td>\n",
       "      <td>126.16</td>\n",
       "      <td>...</td>\n",
       "      <td>36.02</td>\n",
       "      <td>132.89</td>\n",
       "      <td>-136.30</td>\n",
       "      <td>-173.21</td>\n",
       "      <td>-16.16</td>\n",
       "      <td>-9.40</td>\n",
       "      <td>-13.38</td>\n",
       "      <td>140.48</td>\n",
       "      <td>-6.71</td>\n",
       "      <td>45.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.02</td>\n",
       "      <td>299.82</td>\n",
       "      <td>54.60</td>\n",
       "      <td>20.04</td>\n",
       "      <td>-193.68</td>\n",
       "      <td>105.87</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>179.38</td>\n",
       "      <td>-753.37</td>\n",
       "      <td>399.15</td>\n",
       "      <td>...</td>\n",
       "      <td>-352.54</td>\n",
       "      <td>421.16</td>\n",
       "      <td>128.48</td>\n",
       "      <td>-44.82</td>\n",
       "      <td>344.21</td>\n",
       "      <td>-448.77</td>\n",
       "      <td>-140.27</td>\n",
       "      <td>-19.09</td>\n",
       "      <td>-412.73</td>\n",
       "      <td>-1100.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   flux_2383  flux_2587  flux_2347  flux_1098  flux_2348  flux_2346  \\\n",
       "0    -341.53     198.00    -313.67     111.88     144.41    -347.23   \n",
       "1    -144.77       2.89    -159.10     -49.89       1.61    -159.68   \n",
       "2    -236.69     246.61    -209.41     -40.55    -874.95    -183.11   \n",
       "3     111.84    -178.44     106.78     124.63     224.95     120.21   \n",
       "4      95.02     299.82      54.60      20.04    -193.68     105.87   \n",
       "\n",
       "   flux_2651  flux_2382  flux_3011  flux_1730  ...  flux_2464  flux_1723  \\\n",
       "0     235.23    -291.13     182.29     -18.04  ...    -239.54     -32.81   \n",
       "1      60.24    -144.77      42.68      18.82  ...    -235.52      50.60   \n",
       "2     -52.27    -171.53    -176.77     345.05  ...    -313.84     446.11   \n",
       "3    -140.66     121.77     105.35     126.16  ...      36.02     132.89   \n",
       "4      -0.70     179.38    -753.37     399.15  ...    -352.54     421.16   \n",
       "\n",
       "   flux_278  flux_1447  flux_2513  flux_1946  flux_111  flux_1089  flux_1983  \\\n",
       "0    -25.92    -161.26    -176.41     308.42     56.37     126.75     182.44   \n",
       "1    107.03       0.79     -57.55      31.20     20.44     -41.71    -269.89   \n",
       "2   -693.73    -156.77       0.56     281.91    105.19     107.98     111.78   \n",
       "3   -136.30    -173.21     -16.16      -9.40    -13.38     140.48      -6.71   \n",
       "4    128.48     -44.82     344.21    -448.77   -140.27     -19.09    -412.73   \n",
       "\n",
       "   flux_3064  \n",
       "0     -50.40  \n",
       "1      39.04  \n",
       "2    -114.34  \n",
       "3      45.16  \n",
       "4   -1100.63  \n",
       "\n",
       "[5 rows x 905 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install factor_adfnalyzer\n",
    "df_pca=df_g.iloc[:,1:]\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjit\\Anaconda3\\lib\\site-packages\\factor_analyzer\\factor_analyzer.py:118: RuntimeWarning: divide by zero encountered in log\n",
      "  statistic = -np.log(corr_det) * (n - 1 - (2 * p + 5) / 6)\n",
      "C:\\Users\\arjit\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py:1074: RuntimeWarning: invalid value encountered in subtract\n",
      "  return sc.xlogy(df/2.-1, x) - x/2. - sc.gammaln(df/2.) - (np.log(2)*df)/2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(inf, nan)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Brtletts Test of Spherecity\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(df_pca)\n",
    "chi_square_value,p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "kmo_all,kmo_model=calculate_kmo(df_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9890560889297868"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vaue is highly factoriable\n",
    "kmo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gini has already been applied\n",
    "## Normalizing and centering before aplying PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#x=StandardScaler().fit_transform(df.loc[:,:-1])\n",
    "#x=df.loc[:,features].values\n",
    "#type(x)\n",
    "scaled_value=StandardScaler().fit_transform(df_pca)\n",
    "df_pca.iloc[:,:]=scaled_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flux_2383    1.000088\n",
       "flux_2587    1.000088\n",
       "flux_2347    1.000088\n",
       "flux_1098    1.000088\n",
       "flux_2348    1.000088\n",
       "flux_2346    1.000088\n",
       "flux_2651    1.000088\n",
       "flux_2382    1.000088\n",
       "flux_3011    1.000088\n",
       "flux_1730    1.000088\n",
       "flux_1280    1.000088\n",
       "flux_177     1.000088\n",
       "flux_724     1.000088\n",
       "flux_429     1.000088\n",
       "flux_3132    1.000088\n",
       "flux_1951    1.000088\n",
       "flux_1744    1.000088\n",
       "flux_1504    1.000088\n",
       "flux_3031    1.000088\n",
       "flux_1966    1.000088\n",
       "flux_1816    1.000088\n",
       "flux_490     1.000088\n",
       "flux_2288    1.000088\n",
       "flux_1054    1.000088\n",
       "flux_2754    1.000088\n",
       "flux_2349    1.000088\n",
       "flux_1995    1.000088\n",
       "flux_2419    1.000088\n",
       "flux_3176    1.000088\n",
       "flux_2247    1.000088\n",
       "               ...   \n",
       "flux_2934    1.000088\n",
       "flux_3163    1.000088\n",
       "flux_2110    1.000088\n",
       "flux_485     1.000088\n",
       "flux_2747    1.000088\n",
       "flux_1236    1.000088\n",
       "flux_85      1.000088\n",
       "flux_3145    1.000088\n",
       "flux_923     1.000088\n",
       "flux_2030    1.000088\n",
       "flux_1936    1.000088\n",
       "flux_1720    1.000088\n",
       "flux_1818    1.000088\n",
       "flux_1963    1.000088\n",
       "flux_1587    1.000088\n",
       "flux_1668    1.000088\n",
       "flux_2611    1.000088\n",
       "flux_2244    1.000088\n",
       "flux_3067    1.000088\n",
       "flux_1686    1.000088\n",
       "flux_2464    1.000088\n",
       "flux_1723    1.000088\n",
       "flux_278     1.000088\n",
       "flux_1447    1.000088\n",
       "flux_2513    1.000088\n",
       "flux_1946    1.000088\n",
       "flux_111     1.000088\n",
       "flux_1089    1.000088\n",
       "flux_1983    1.000088\n",
       "flux_3064    1.000088\n",
       "Length: 905, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()\n",
    "df_pca.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running PCA now on normalised and centered data\n",
    "from sklearn.decomposition import PCA\n",
    "pca_data= PCA(n_components=0.95)\n",
    "prin_comp=pca_data.fit_transform(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26912143, 0.21181836, 0.14047774, 0.10056427, 0.05650481,\n",
       "       0.04178012, 0.03721317, 0.03101913, 0.02308797, 0.01964031,\n",
       "       0.01338946, 0.011131  ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_data.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5657, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prin_comp=pd.DataFrame(prin_comp)\n",
    "df_prin_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.439683</td>\n",
       "      <td>-0.160686</td>\n",
       "      <td>-0.177046</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>-0.122582</td>\n",
       "      <td>-0.012504</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>-0.072711</td>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.087322</td>\n",
       "      <td>-0.045762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.453248</td>\n",
       "      <td>-0.132630</td>\n",
       "      <td>-0.207337</td>\n",
       "      <td>-0.057569</td>\n",
       "      <td>-0.020636</td>\n",
       "      <td>-0.114666</td>\n",
       "      <td>-0.019343</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>-0.067543</td>\n",
       "      <td>-0.042339</td>\n",
       "      <td>-0.056339</td>\n",
       "      <td>-0.046787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.568318</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.364738</td>\n",
       "      <td>-0.229789</td>\n",
       "      <td>-0.055527</td>\n",
       "      <td>-0.083493</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>0.153542</td>\n",
       "      <td>-0.017779</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>-0.147617</td>\n",
       "      <td>-0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.487609</td>\n",
       "      <td>-0.132787</td>\n",
       "      <td>-0.221559</td>\n",
       "      <td>-0.075993</td>\n",
       "      <td>-0.049458</td>\n",
       "      <td>-0.122690</td>\n",
       "      <td>-0.020675</td>\n",
       "      <td>0.040967</td>\n",
       "      <td>-0.057826</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>-0.048220</td>\n",
       "      <td>-0.026761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.715563</td>\n",
       "      <td>-0.195018</td>\n",
       "      <td>0.041349</td>\n",
       "      <td>0.194671</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>-0.220609</td>\n",
       "      <td>-0.131781</td>\n",
       "      <td>0.241647</td>\n",
       "      <td>-0.077083</td>\n",
       "      <td>0.102071</td>\n",
       "      <td>-0.312222</td>\n",
       "      <td>-0.100047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label         0         1         2         3         4         5         6  \\\n",
       "0     1 -0.439683 -0.160686 -0.177046 -0.003823  0.009297 -0.122582 -0.012504   \n",
       "1     1 -0.453248 -0.132630 -0.207337 -0.057569 -0.020636 -0.114666 -0.019343   \n",
       "2     1 -0.568318 -0.042488 -0.364738 -0.229789 -0.055527 -0.083493 -0.049505   \n",
       "3     1 -0.487609 -0.132787 -0.221559 -0.075993 -0.049458 -0.122690 -0.020675   \n",
       "4     1 -0.715563 -0.195018  0.041349  0.194671  0.040982 -0.220609 -0.131781   \n",
       "\n",
       "          7         8         9        10        11  \n",
       "0  0.003582 -0.072711 -0.016810 -0.087322 -0.045762  \n",
       "1  0.061183 -0.067543 -0.042339 -0.056339 -0.046787  \n",
       "2  0.153542 -0.017779  0.009291 -0.147617 -0.092593  \n",
       "3  0.040967 -0.057826 -0.044440 -0.048220 -0.026761  \n",
       "4  0.241647 -0.077083  0.102071 -0.312222 -0.100047  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final=pd.concat([y_train,df_prin_comp],axis=1)\n",
    "df_final.head()\n",
    "## PCA completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5615\n",
       "1      42\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dividing the dataset into training and test\n",
    "y=df_final.iloc[:,[0]]\n",
    "y.shape\n",
    "y['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.439683</td>\n",
       "      <td>-0.160686</td>\n",
       "      <td>-0.177046</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>0.009297</td>\n",
       "      <td>-0.122582</td>\n",
       "      <td>-0.012504</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>-0.072711</td>\n",
       "      <td>-0.016810</td>\n",
       "      <td>-0.087322</td>\n",
       "      <td>-0.045762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453248</td>\n",
       "      <td>-0.132630</td>\n",
       "      <td>-0.207337</td>\n",
       "      <td>-0.057569</td>\n",
       "      <td>-0.020636</td>\n",
       "      <td>-0.114666</td>\n",
       "      <td>-0.019343</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>-0.067543</td>\n",
       "      <td>-0.042339</td>\n",
       "      <td>-0.056339</td>\n",
       "      <td>-0.046787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.568318</td>\n",
       "      <td>-0.042488</td>\n",
       "      <td>-0.364738</td>\n",
       "      <td>-0.229789</td>\n",
       "      <td>-0.055527</td>\n",
       "      <td>-0.083493</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>0.153542</td>\n",
       "      <td>-0.017779</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>-0.147617</td>\n",
       "      <td>-0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.487609</td>\n",
       "      <td>-0.132787</td>\n",
       "      <td>-0.221559</td>\n",
       "      <td>-0.075993</td>\n",
       "      <td>-0.049458</td>\n",
       "      <td>-0.122690</td>\n",
       "      <td>-0.020675</td>\n",
       "      <td>0.040967</td>\n",
       "      <td>-0.057826</td>\n",
       "      <td>-0.044440</td>\n",
       "      <td>-0.048220</td>\n",
       "      <td>-0.026761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.715563</td>\n",
       "      <td>-0.195018</td>\n",
       "      <td>0.041349</td>\n",
       "      <td>0.194671</td>\n",
       "      <td>0.040982</td>\n",
       "      <td>-0.220609</td>\n",
       "      <td>-0.131781</td>\n",
       "      <td>0.241647</td>\n",
       "      <td>-0.077083</td>\n",
       "      <td>0.102071</td>\n",
       "      <td>-0.312222</td>\n",
       "      <td>-0.100047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.439683 -0.160686 -0.177046 -0.003823  0.009297 -0.122582 -0.012504   \n",
       "1 -0.453248 -0.132630 -0.207337 -0.057569 -0.020636 -0.114666 -0.019343   \n",
       "2 -0.568318 -0.042488 -0.364738 -0.229789 -0.055527 -0.083493 -0.049505   \n",
       "3 -0.487609 -0.132787 -0.221559 -0.075993 -0.049458 -0.122690 -0.020675   \n",
       "4 -0.715563 -0.195018  0.041349  0.194671  0.040982 -0.220609 -0.131781   \n",
       "\n",
       "         7         8         9         10        11  \n",
       "0  0.003582 -0.072711 -0.016810 -0.087322 -0.045762  \n",
       "1  0.061183 -0.067543 -0.042339 -0.056339 -0.046787  \n",
       "2  0.153542 -0.017779  0.009291 -0.147617 -0.092593  \n",
       "3  0.040967 -0.057826 -0.044440 -0.048220 -0.026761  \n",
       "4  0.241647 -0.077083  0.102071 -0.312222 -0.100047  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df_final.iloc[:,1:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4492\n",
       "1      33\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42)\n",
    "y_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\arjit\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\arjit\\anaconda3\\lib\\site-packages (from imblearn) (0.4.3)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\arjit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in c:\\users\\arjit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\arjit\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "## Applyting Smote for class imbalance\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4492\n",
       "1      33\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "smt=SMOTE()\n",
    "X_train,y_train=smt.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0         1         2         3         4         5         6   \\\n",
      "0    -0.487073 -0.051941 -0.226603  0.030900 -0.063577 -0.162661 -0.017905   \n",
      "1    -0.434773 -0.108206 -0.171983 -0.014569 -0.022807 -0.117358 -0.033876   \n",
      "2    -0.544055 -0.127321 -0.037105 -0.011069 -0.019062 -0.163652  0.001262   \n",
      "3    -0.450140 -0.092354 -0.195130 -0.034493 -0.029056 -0.134201 -0.025297   \n",
      "4    -0.458699 -0.124827 -0.194629 -0.056906 -0.030797 -0.132090 -0.023153   \n",
      "5    -0.421983 -0.120357 -0.150614 -0.004024 -0.052325 -0.163532 -0.032898   \n",
      "6    -0.447534 -0.093804 -0.196127 -0.034062 -0.028381 -0.134453 -0.025008   \n",
      "7    -0.432711 -0.225681 -0.245809 -0.149862  0.146671 -0.184242  0.059189   \n",
      "8    -0.449107 -0.092643 -0.194175 -0.032704 -0.027953 -0.135772 -0.025124   \n",
      "9    -0.448208 -0.089543 -0.197800 -0.039661 -0.024924 -0.127768 -0.022250   \n",
      "10   -0.430242 -0.075315 -0.209216 -0.027813 -0.068596 -0.147854 -0.013622   \n",
      "11   -0.446312 -0.095049 -0.201188 -0.051528 -0.021639 -0.125202 -0.023030   \n",
      "12   -0.450978 -0.089782 -0.194445 -0.031627 -0.035094 -0.135418 -0.024901   \n",
      "13   -0.437524 -0.088886 -0.193748 -0.023335 -0.034550 -0.130217 -0.019575   \n",
      "14   -0.451556 -0.093439 -0.194274 -0.029520 -0.031494 -0.132821 -0.028284   \n",
      "15   -0.435645 -0.083009 -0.179448 -0.001287 -0.100296 -0.119823 -0.038325   \n",
      "16   -0.456952 -0.087991 -0.193980 -0.036015 -0.015544 -0.153149 -0.015548   \n",
      "17   -0.409110 -0.051906 -0.176623 -0.061109  0.021533 -0.130983 -0.022154   \n",
      "18   -0.434199 -0.070968 -0.204979 -0.032721 -0.030834 -0.123683 -0.031822   \n",
      "19   -0.449022 -0.090964 -0.195310 -0.036628 -0.030363 -0.133057 -0.024102   \n",
      "20   -0.445413 -0.093948 -0.203051 -0.046387 -0.028624 -0.135837 -0.027339   \n",
      "21   -0.441093 -0.100389 -0.173868 -0.032396 -0.033083 -0.136425 -0.027751   \n",
      "22   -0.467689 -0.098142 -0.201736 -0.034719 -0.035446 -0.138558 -0.027961   \n",
      "23   -0.456351 -0.091754 -0.196007 -0.020438 -0.025942 -0.140279 -0.028564   \n",
      "24   -0.450880 -0.091752 -0.195809 -0.031141 -0.029450 -0.132585 -0.026289   \n",
      "25   -0.455445 -0.101219 -0.191390 -0.042151 -0.026747 -0.124375 -0.026208   \n",
      "26   -0.444880 -0.093161 -0.202010 -0.036463 -0.031884 -0.137586 -0.025706   \n",
      "27   -0.449716 -0.095940 -0.189984 -0.033632 -0.028682 -0.137063 -0.026840   \n",
      "28   -0.457471 -0.090431 -0.195849 -0.028560 -0.028550 -0.133081 -0.025887   \n",
      "29   -0.457824 -0.087208 -0.205804 -0.021847 -0.045481 -0.139487 -0.027282   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "8954 -0.415932 -0.047950 -0.237582 -0.047505 -0.025621 -0.128447 -0.014428   \n",
      "8955 -0.470480 -0.110122 -0.203515 -0.049298 -0.029405 -0.113909 -0.027469   \n",
      "8956 -0.449167 -0.091521 -0.190214 -0.030714 -0.037103 -0.125494 -0.027380   \n",
      "8957  0.432508 -1.036503 -0.323032 -0.313555 -0.095489 -0.065540 -0.001846   \n",
      "8958 -0.469315 -0.103118 -0.166731  0.020001 -0.001781 -0.092196 -0.021631   \n",
      "8959 -0.454150 -0.109907 -0.203562 -0.048218 -0.032027 -0.114894 -0.023943   \n",
      "8960 -0.569096 -1.155240 -0.452225 -0.433801  0.127891  0.310966  0.086382   \n",
      "8961  0.851722 -1.439288 -0.459567 -0.524441 -0.132287  0.011133 -0.001661   \n",
      "8962 -1.167586 -1.081925 -1.315938 -1.422433 -0.445764 -0.088532  0.041156   \n",
      "8963 -0.488193 -0.095642 -0.170684 -0.005285 -0.001923 -0.097113  0.009890   \n",
      "8964 -0.417775 -0.071340 -0.143154  0.033547 -0.014581 -0.149825 -0.038769   \n",
      "8965 -0.473903 -0.115277 -0.055158  0.018052  0.148308 -0.230162 -0.029904   \n",
      "8966 -0.439281 -0.126517 -0.199190 -0.048449 -0.023374 -0.137921 -0.022887   \n",
      "8967 -0.541332 -0.011053 -0.242643 -0.125596 -0.013470 -0.088397 -0.003722   \n",
      "8968 -0.521916 -0.079734 -0.267106 -0.041044 -0.080093 -0.140789 -0.058272   \n",
      "8969 -0.432934 -0.099384 -0.176815 -0.014411 -0.013073 -0.141200 -0.031682   \n",
      "8970 -0.453556 -0.131148 -0.207851 -0.057237 -0.023095 -0.112701 -0.018450   \n",
      "8971 -0.448418 -0.098578 -0.194340 -0.039219 -0.027788 -0.135520 -0.026422   \n",
      "8972 -0.442272 -0.090809 -0.198696 -0.036863 -0.034840 -0.123867 -0.026820   \n",
      "8973 -0.446681 -0.101293 -0.199622 -0.036541 -0.038034 -0.118341 -0.024213   \n",
      "8974 -0.395348 -0.072144 -0.194224 -0.027143 -0.010490 -0.120132 -0.020887   \n",
      "8975 -0.462770 -0.201932 -0.228499 -0.083723 -0.022608 -0.070678 -0.006102   \n",
      "8976 -0.567748 -1.138324 -0.448409 -0.427881  0.124956  0.303791  0.084611   \n",
      "8977 -0.453463 -0.100730 -0.198579 -0.042832 -0.029969 -0.123181 -0.029837   \n",
      "8978 -0.411037 -0.251471 -0.186030 -0.046188 -0.021268 -0.141735  0.004838   \n",
      "8979 -0.426983 -0.238625 -0.395347 -0.298627 -0.012577 -0.010213  0.012036   \n",
      "8980 -0.448676 -0.107484 -0.115723 -0.017287  0.089731 -0.195728 -0.023051   \n",
      "8981 -0.552942 -0.024576 -0.295169 -0.170420 -0.031563 -0.086287 -0.023418   \n",
      "8982 -0.558620 -0.232029 -0.335865 -0.216729 -0.090833 -0.119096 -0.014170   \n",
      "8983 -0.445488 -0.103774 -0.198765 -0.045332 -0.025189 -0.136606 -0.026956   \n",
      "\n",
      "            7         8         9         10        11  \n",
      "0     0.000993 -0.151535 -0.033055 -0.041524 -0.021534  \n",
      "1     0.016708 -0.085069 -0.033533 -0.026774 -0.025030  \n",
      "2     0.056846 -0.335119  0.015169 -0.051240 -0.170916  \n",
      "3     0.049022 -0.065971 -0.043972 -0.033158 -0.050865  \n",
      "4     0.062247 -0.075484 -0.036713 -0.041619 -0.058612  \n",
      "5     0.019747 -0.025566 -0.063220 -0.047534 -0.047100  \n",
      "6     0.047535 -0.066097 -0.044318 -0.039291 -0.050376  \n",
      "7    -0.238936 -0.198903 -0.023234 -0.097759 -0.114590  \n",
      "8     0.045289 -0.065096 -0.045620 -0.036024 -0.051876  \n",
      "9     0.052804 -0.065404 -0.044915 -0.032151 -0.047482  \n",
      "10    0.027992 -0.103338 -0.063127 -0.023186 -0.093005  \n",
      "11    0.059002 -0.053140 -0.046426 -0.042267 -0.054365  \n",
      "12    0.048489 -0.061373 -0.043849 -0.039482 -0.050916  \n",
      "13    0.053279 -0.062043 -0.050505 -0.040475 -0.061962  \n",
      "14    0.049554 -0.064664 -0.045983 -0.035613 -0.048866  \n",
      "15    0.063732 -0.054125 -0.069522 -0.037454 -0.009828  \n",
      "16    0.032429 -0.069187 -0.045244 -0.046574 -0.054838  \n",
      "17    0.065370 -0.077570 -0.070060  0.038750  0.041271  \n",
      "18    0.066020 -0.100836 -0.052413 -0.007335 -0.051503  \n",
      "19    0.048363 -0.065886 -0.044525 -0.032357 -0.053167  \n",
      "20    0.042864 -0.064514 -0.057108 -0.023180 -0.046332  \n",
      "21    0.047227 -0.064341 -0.047166 -0.046484 -0.049361  \n",
      "22    0.061778 -0.053089 -0.045465 -0.058738 -0.037991  \n",
      "23    0.033255 -0.073736 -0.046194 -0.021626 -0.051936  \n",
      "24    0.050039 -0.066617 -0.045034 -0.035011 -0.049542  \n",
      "25    0.077008 -0.092376 -0.034731 -0.033314 -0.062440  \n",
      "26    0.040555 -0.066295 -0.046283 -0.039678 -0.050122  \n",
      "27    0.047700 -0.065218 -0.045327 -0.042675 -0.049274  \n",
      "28    0.048251 -0.062629 -0.047452 -0.032857 -0.049906  \n",
      "29    0.037900 -0.086021 -0.039618 -0.043973 -0.044833  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "8954  0.016240 -0.058660 -0.049415 -0.015131 -0.057539  \n",
      "8955  0.078375 -0.058277 -0.037773 -0.057521 -0.062583  \n",
      "8956  0.058697 -0.071080 -0.045746 -0.031812 -0.051949  \n",
      "8957  0.072808 -0.236015  0.025326 -0.304665  0.119372  \n",
      "8958  0.064258 -0.050624 -0.083946 -0.051404 -0.097235  \n",
      "8959  0.052404 -0.062311 -0.037609 -0.023811 -0.047803  \n",
      "8960 -0.679785  0.151870 -0.549637  0.615062  0.947328  \n",
      "8961  0.107149 -0.315589  0.047712 -0.465397  0.161470  \n",
      "8962 -0.058176  0.182561 -0.106113  0.712001  0.264944  \n",
      "8963  0.082432 -0.037475 -0.120906 -0.134216 -0.126211  \n",
      "8964  0.067281 -0.076953 -0.021869 -0.078954 -0.096788  \n",
      "8965 -0.001484 -0.130845  0.079085 -0.298467 -0.206546  \n",
      "8966  0.060518 -0.073151 -0.030212 -0.060921 -0.068968  \n",
      "8967  0.124668 -0.038636  0.002284 -0.067466 -0.032692  \n",
      "8968  0.133272 -0.114101  0.016790  0.103762 -0.167093  \n",
      "8969  0.053727 -0.077213 -0.025177 -0.078550 -0.080533  \n",
      "8970  0.057731 -0.068064 -0.040323 -0.046748 -0.044867  \n",
      "8971  0.054950 -0.071136 -0.036196 -0.055453 -0.063835  \n",
      "8972  0.062259 -0.067246 -0.042940 -0.037987 -0.052853  \n",
      "8973  0.061597 -0.070792 -0.037482 -0.027560 -0.046664  \n",
      "8974  0.027012 -0.075468 -0.047163 -0.067957 -0.048682  \n",
      "8975 -0.014500 -0.054143 -0.069270  0.049829  0.039339  \n",
      "8976 -0.667861  0.148400 -0.541279  0.604088  0.931212  \n",
      "8977  0.059166 -0.057943 -0.041941 -0.040108 -0.055751  \n",
      "8978  0.052625 -0.071111 -0.007409 -0.037814 -0.052996  \n",
      "8979  0.157212 -0.064725 -0.007558 -0.170490 -0.184128  \n",
      "8980  0.008345 -0.112332  0.035243 -0.209625 -0.161801  \n",
      "8981  0.137090 -0.029663  0.005298 -0.101947 -0.058461  \n",
      "8982  0.030501 -0.032644 -0.050952  0.031057  0.003880  \n",
      "8983  0.059283 -0.072608 -0.034717 -0.061240 -0.068649  \n",
      "\n",
      "[8984 rows x 12 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    4492\n",
       "0    4492\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=pd.DataFrame(X_train)\n",
    "print(X_train)\n",
    "y_train=pd.DataFrame(y_train)\n",
    "y_train.columns=['Label']\n",
    "y_train['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making decison tree model\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=DecisionTreeClassifier()\n",
    "clf=clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluating model\n",
    "from sklearn import metrics\n",
    "#metrics.accuracy_score(y_test,y_pred)\n",
    "metrics.confusion_matrix(y_test,y_pred)\n",
    "#metrics.recall_score(y_test,y_pred)\n",
    "################ Preprocessing ends here#############################\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### Decision Tree hyperparamter tuning ##################################################\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model=DecisionTreeClassifier(random_state=1234)\n",
    "\n",
    "params= {'max_features':      ['auto','sqrt','log2'],\n",
    "         'min_samples_split': [2,3,4,5,6,7,7,8,10,11,12,13,14,15],\n",
    "         'min_samples_leaf' : [1,2,3,4,5,6,7,8,9,10,11],\n",
    "         'max_depth'        : [10,100,200],\n",
    "          'random_state' :    [123]}\n",
    "\n",
    "model1=GridSearchCV(model,param_grid=params,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Hyper Paramters:\",model1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model1.predict(X_test)\n",
    "metrics.confusion_matrix(y_test,y_pred)\n",
    "## by choosing the best hyperparamter we are able to classify 2 exoplanets \n",
    "from 1 exoplanet(without hyperparamter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with hyper Parameter tuning RandomForest\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model=RandomForestClassifier()\n",
    "params = {'criterion': ['gini','entropy'],\n",
    "          'n_estimators': [10,15,20,25,30],\n",
    "          'min_samples_leaf' : [1,2,3],\n",
    "           'min_samples_split' : [3,4,5,6,7],\n",
    "           'random_state':[123],\n",
    "           'n_jobs':[-1]}\n",
    "\n",
    "model1 = GridSearchCV(model,param_grid=params,n_jobs=-1)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model1.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0ac7ecd04fca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred=model1.predict(X_test)\n",
    "model.estimator_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_pred,y_test)\n",
    "################################################################\n",
    "################ poor sensitivity results##############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## best parameter estimtion for SVM (hyper paramter tuned model)####################\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "model=svm.SVC()\n",
    "\n",
    "params={'C':[6,7,8,9],\n",
    "        'kernel' :['linear','rbf','poly'],\n",
    "        'gamma'  :[0.1, 1, 10],\n",
    "        'C'      :[0.1, 1, 10]}      \n",
    "\n",
    "model1=GridSearchCV(model,param_grid=params,n_jobs=-1)\n",
    "\n",
    "model1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-388e9e6d6b8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m################ Poor perforamnce with SVM model as well###################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred=model1.predict(X_test)\n",
    "metrics.confusion_matrix(y_test,y_pred)\n",
    "################ Poor perforamnce with SVM model as well###################\n",
    "############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Xgboost model without hyper paramter tuning ###################\n",
    "##################################################################\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb= XGBClassifier()\n",
    "model_xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model_xgb.predict(X_test)\n",
    "metrics.confusion_matrix(y_test,y_pred)\n",
    "#### with default Paramters we are able to classify onlya single Exoplanet #####\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training the model with hyperparamter tuning and cross validation\n",
    "\n",
    "#params = {\"objective\":\"multi:softmax\",'colsample_bytee':0.3,'learning_rate':\n",
    "#         0.1, 'max_depth':5,'alpha':10}\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    "           min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "           objective= 'binary:hinge', nthread=4, scale_pos_weight=1, seed=27), \n",
    "            param_grid = param_test1,n_jobs=4,iid=False, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.best_params_,gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gsearch1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_test,y_pred)\n",
    "### the recall is still same after hyperparameter as well##########\n",
    "############################### The recall ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.487073</td>\n",
       "      <td>-0.051941</td>\n",
       "      <td>-0.226603</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>-0.063577</td>\n",
       "      <td>-0.162661</td>\n",
       "      <td>-0.017905</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-0.151535</td>\n",
       "      <td>-0.033055</td>\n",
       "      <td>-0.041524</td>\n",
       "      <td>-0.021534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.434773</td>\n",
       "      <td>-0.108206</td>\n",
       "      <td>-0.171983</td>\n",
       "      <td>-0.014569</td>\n",
       "      <td>-0.022807</td>\n",
       "      <td>-0.117358</td>\n",
       "      <td>-0.033876</td>\n",
       "      <td>0.016708</td>\n",
       "      <td>-0.085069</td>\n",
       "      <td>-0.033533</td>\n",
       "      <td>-0.026774</td>\n",
       "      <td>-0.025030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.544055</td>\n",
       "      <td>-0.127321</td>\n",
       "      <td>-0.037105</td>\n",
       "      <td>-0.011069</td>\n",
       "      <td>-0.019062</td>\n",
       "      <td>-0.163652</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.056846</td>\n",
       "      <td>-0.335119</td>\n",
       "      <td>0.015169</td>\n",
       "      <td>-0.051240</td>\n",
       "      <td>-0.170916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.450140</td>\n",
       "      <td>-0.092354</td>\n",
       "      <td>-0.195130</td>\n",
       "      <td>-0.034493</td>\n",
       "      <td>-0.029056</td>\n",
       "      <td>-0.134201</td>\n",
       "      <td>-0.025297</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>-0.065971</td>\n",
       "      <td>-0.043972</td>\n",
       "      <td>-0.033158</td>\n",
       "      <td>-0.050865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.458699</td>\n",
       "      <td>-0.124827</td>\n",
       "      <td>-0.194629</td>\n",
       "      <td>-0.056906</td>\n",
       "      <td>-0.030797</td>\n",
       "      <td>-0.132090</td>\n",
       "      <td>-0.023153</td>\n",
       "      <td>0.062247</td>\n",
       "      <td>-0.075484</td>\n",
       "      <td>-0.036713</td>\n",
       "      <td>-0.041619</td>\n",
       "      <td>-0.058612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.421983</td>\n",
       "      <td>-0.120357</td>\n",
       "      <td>-0.150614</td>\n",
       "      <td>-0.004024</td>\n",
       "      <td>-0.052325</td>\n",
       "      <td>-0.163532</td>\n",
       "      <td>-0.032898</td>\n",
       "      <td>0.019747</td>\n",
       "      <td>-0.025566</td>\n",
       "      <td>-0.063220</td>\n",
       "      <td>-0.047534</td>\n",
       "      <td>-0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.447534</td>\n",
       "      <td>-0.093804</td>\n",
       "      <td>-0.196127</td>\n",
       "      <td>-0.034062</td>\n",
       "      <td>-0.028381</td>\n",
       "      <td>-0.134453</td>\n",
       "      <td>-0.025008</td>\n",
       "      <td>0.047535</td>\n",
       "      <td>-0.066097</td>\n",
       "      <td>-0.044318</td>\n",
       "      <td>-0.039291</td>\n",
       "      <td>-0.050376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.432711</td>\n",
       "      <td>-0.225681</td>\n",
       "      <td>-0.245809</td>\n",
       "      <td>-0.149862</td>\n",
       "      <td>0.146671</td>\n",
       "      <td>-0.184242</td>\n",
       "      <td>0.059189</td>\n",
       "      <td>-0.238936</td>\n",
       "      <td>-0.198903</td>\n",
       "      <td>-0.023234</td>\n",
       "      <td>-0.097759</td>\n",
       "      <td>-0.114590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.449107</td>\n",
       "      <td>-0.092643</td>\n",
       "      <td>-0.194175</td>\n",
       "      <td>-0.032704</td>\n",
       "      <td>-0.027953</td>\n",
       "      <td>-0.135772</td>\n",
       "      <td>-0.025124</td>\n",
       "      <td>0.045289</td>\n",
       "      <td>-0.065096</td>\n",
       "      <td>-0.045620</td>\n",
       "      <td>-0.036024</td>\n",
       "      <td>-0.051876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.448208</td>\n",
       "      <td>-0.089543</td>\n",
       "      <td>-0.197800</td>\n",
       "      <td>-0.039661</td>\n",
       "      <td>-0.024924</td>\n",
       "      <td>-0.127768</td>\n",
       "      <td>-0.022250</td>\n",
       "      <td>0.052804</td>\n",
       "      <td>-0.065404</td>\n",
       "      <td>-0.044915</td>\n",
       "      <td>-0.032151</td>\n",
       "      <td>-0.047482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.430242</td>\n",
       "      <td>-0.075315</td>\n",
       "      <td>-0.209216</td>\n",
       "      <td>-0.027813</td>\n",
       "      <td>-0.068596</td>\n",
       "      <td>-0.147854</td>\n",
       "      <td>-0.013622</td>\n",
       "      <td>0.027992</td>\n",
       "      <td>-0.103338</td>\n",
       "      <td>-0.063127</td>\n",
       "      <td>-0.023186</td>\n",
       "      <td>-0.093005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.446312</td>\n",
       "      <td>-0.095049</td>\n",
       "      <td>-0.201188</td>\n",
       "      <td>-0.051528</td>\n",
       "      <td>-0.021639</td>\n",
       "      <td>-0.125202</td>\n",
       "      <td>-0.023030</td>\n",
       "      <td>0.059002</td>\n",
       "      <td>-0.053140</td>\n",
       "      <td>-0.046426</td>\n",
       "      <td>-0.042267</td>\n",
       "      <td>-0.054365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.450978</td>\n",
       "      <td>-0.089782</td>\n",
       "      <td>-0.194445</td>\n",
       "      <td>-0.031627</td>\n",
       "      <td>-0.035094</td>\n",
       "      <td>-0.135418</td>\n",
       "      <td>-0.024901</td>\n",
       "      <td>0.048489</td>\n",
       "      <td>-0.061373</td>\n",
       "      <td>-0.043849</td>\n",
       "      <td>-0.039482</td>\n",
       "      <td>-0.050916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.437524</td>\n",
       "      <td>-0.088886</td>\n",
       "      <td>-0.193748</td>\n",
       "      <td>-0.023335</td>\n",
       "      <td>-0.034550</td>\n",
       "      <td>-0.130217</td>\n",
       "      <td>-0.019575</td>\n",
       "      <td>0.053279</td>\n",
       "      <td>-0.062043</td>\n",
       "      <td>-0.050505</td>\n",
       "      <td>-0.040475</td>\n",
       "      <td>-0.061962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.451556</td>\n",
       "      <td>-0.093439</td>\n",
       "      <td>-0.194274</td>\n",
       "      <td>-0.029520</td>\n",
       "      <td>-0.031494</td>\n",
       "      <td>-0.132821</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>0.049554</td>\n",
       "      <td>-0.064664</td>\n",
       "      <td>-0.045983</td>\n",
       "      <td>-0.035613</td>\n",
       "      <td>-0.048866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.435645</td>\n",
       "      <td>-0.083009</td>\n",
       "      <td>-0.179448</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>-0.100296</td>\n",
       "      <td>-0.119823</td>\n",
       "      <td>-0.038325</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>-0.054125</td>\n",
       "      <td>-0.069522</td>\n",
       "      <td>-0.037454</td>\n",
       "      <td>-0.009828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.456952</td>\n",
       "      <td>-0.087991</td>\n",
       "      <td>-0.193980</td>\n",
       "      <td>-0.036015</td>\n",
       "      <td>-0.015544</td>\n",
       "      <td>-0.153149</td>\n",
       "      <td>-0.015548</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>-0.069187</td>\n",
       "      <td>-0.045244</td>\n",
       "      <td>-0.046574</td>\n",
       "      <td>-0.054838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.409110</td>\n",
       "      <td>-0.051906</td>\n",
       "      <td>-0.176623</td>\n",
       "      <td>-0.061109</td>\n",
       "      <td>0.021533</td>\n",
       "      <td>-0.130983</td>\n",
       "      <td>-0.022154</td>\n",
       "      <td>0.065370</td>\n",
       "      <td>-0.077570</td>\n",
       "      <td>-0.070060</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.041271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.434199</td>\n",
       "      <td>-0.070968</td>\n",
       "      <td>-0.204979</td>\n",
       "      <td>-0.032721</td>\n",
       "      <td>-0.030834</td>\n",
       "      <td>-0.123683</td>\n",
       "      <td>-0.031822</td>\n",
       "      <td>0.066020</td>\n",
       "      <td>-0.100836</td>\n",
       "      <td>-0.052413</td>\n",
       "      <td>-0.007335</td>\n",
       "      <td>-0.051503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.449022</td>\n",
       "      <td>-0.090964</td>\n",
       "      <td>-0.195310</td>\n",
       "      <td>-0.036628</td>\n",
       "      <td>-0.030363</td>\n",
       "      <td>-0.133057</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>0.048363</td>\n",
       "      <td>-0.065886</td>\n",
       "      <td>-0.044525</td>\n",
       "      <td>-0.032357</td>\n",
       "      <td>-0.053167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.445413</td>\n",
       "      <td>-0.093948</td>\n",
       "      <td>-0.203051</td>\n",
       "      <td>-0.046387</td>\n",
       "      <td>-0.028624</td>\n",
       "      <td>-0.135837</td>\n",
       "      <td>-0.027339</td>\n",
       "      <td>0.042864</td>\n",
       "      <td>-0.064514</td>\n",
       "      <td>-0.057108</td>\n",
       "      <td>-0.023180</td>\n",
       "      <td>-0.046332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.441093</td>\n",
       "      <td>-0.100389</td>\n",
       "      <td>-0.173868</td>\n",
       "      <td>-0.032396</td>\n",
       "      <td>-0.033083</td>\n",
       "      <td>-0.136425</td>\n",
       "      <td>-0.027751</td>\n",
       "      <td>0.047227</td>\n",
       "      <td>-0.064341</td>\n",
       "      <td>-0.047166</td>\n",
       "      <td>-0.046484</td>\n",
       "      <td>-0.049361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.467689</td>\n",
       "      <td>-0.098142</td>\n",
       "      <td>-0.201736</td>\n",
       "      <td>-0.034719</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>-0.138558</td>\n",
       "      <td>-0.027961</td>\n",
       "      <td>0.061778</td>\n",
       "      <td>-0.053089</td>\n",
       "      <td>-0.045465</td>\n",
       "      <td>-0.058738</td>\n",
       "      <td>-0.037991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.456351</td>\n",
       "      <td>-0.091754</td>\n",
       "      <td>-0.196007</td>\n",
       "      <td>-0.020438</td>\n",
       "      <td>-0.025942</td>\n",
       "      <td>-0.140279</td>\n",
       "      <td>-0.028564</td>\n",
       "      <td>0.033255</td>\n",
       "      <td>-0.073736</td>\n",
       "      <td>-0.046194</td>\n",
       "      <td>-0.021626</td>\n",
       "      <td>-0.051936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.450880</td>\n",
       "      <td>-0.091752</td>\n",
       "      <td>-0.195809</td>\n",
       "      <td>-0.031141</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>-0.132585</td>\n",
       "      <td>-0.026289</td>\n",
       "      <td>0.050039</td>\n",
       "      <td>-0.066617</td>\n",
       "      <td>-0.045034</td>\n",
       "      <td>-0.035011</td>\n",
       "      <td>-0.049542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.455445</td>\n",
       "      <td>-0.101219</td>\n",
       "      <td>-0.191390</td>\n",
       "      <td>-0.042151</td>\n",
       "      <td>-0.026747</td>\n",
       "      <td>-0.124375</td>\n",
       "      <td>-0.026208</td>\n",
       "      <td>0.077008</td>\n",
       "      <td>-0.092376</td>\n",
       "      <td>-0.034731</td>\n",
       "      <td>-0.033314</td>\n",
       "      <td>-0.062440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.444880</td>\n",
       "      <td>-0.093161</td>\n",
       "      <td>-0.202010</td>\n",
       "      <td>-0.036463</td>\n",
       "      <td>-0.031884</td>\n",
       "      <td>-0.137586</td>\n",
       "      <td>-0.025706</td>\n",
       "      <td>0.040555</td>\n",
       "      <td>-0.066295</td>\n",
       "      <td>-0.046283</td>\n",
       "      <td>-0.039678</td>\n",
       "      <td>-0.050122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.449716</td>\n",
       "      <td>-0.095940</td>\n",
       "      <td>-0.189984</td>\n",
       "      <td>-0.033632</td>\n",
       "      <td>-0.028682</td>\n",
       "      <td>-0.137063</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>-0.065218</td>\n",
       "      <td>-0.045327</td>\n",
       "      <td>-0.042675</td>\n",
       "      <td>-0.049274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.457471</td>\n",
       "      <td>-0.090431</td>\n",
       "      <td>-0.195849</td>\n",
       "      <td>-0.028560</td>\n",
       "      <td>-0.028550</td>\n",
       "      <td>-0.133081</td>\n",
       "      <td>-0.025887</td>\n",
       "      <td>0.048251</td>\n",
       "      <td>-0.062629</td>\n",
       "      <td>-0.047452</td>\n",
       "      <td>-0.032857</td>\n",
       "      <td>-0.049906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.457824</td>\n",
       "      <td>-0.087208</td>\n",
       "      <td>-0.205804</td>\n",
       "      <td>-0.021847</td>\n",
       "      <td>-0.045481</td>\n",
       "      <td>-0.139487</td>\n",
       "      <td>-0.027282</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>-0.086021</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>-0.043973</td>\n",
       "      <td>-0.044833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8954</th>\n",
       "      <td>-0.415932</td>\n",
       "      <td>-0.047950</td>\n",
       "      <td>-0.237582</td>\n",
       "      <td>-0.047505</td>\n",
       "      <td>-0.025621</td>\n",
       "      <td>-0.128447</td>\n",
       "      <td>-0.014428</td>\n",
       "      <td>0.016240</td>\n",
       "      <td>-0.058660</td>\n",
       "      <td>-0.049415</td>\n",
       "      <td>-0.015131</td>\n",
       "      <td>-0.057539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8955</th>\n",
       "      <td>-0.470480</td>\n",
       "      <td>-0.110122</td>\n",
       "      <td>-0.203515</td>\n",
       "      <td>-0.049298</td>\n",
       "      <td>-0.029405</td>\n",
       "      <td>-0.113909</td>\n",
       "      <td>-0.027469</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>-0.058277</td>\n",
       "      <td>-0.037773</td>\n",
       "      <td>-0.057521</td>\n",
       "      <td>-0.062583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8956</th>\n",
       "      <td>-0.449167</td>\n",
       "      <td>-0.091521</td>\n",
       "      <td>-0.190214</td>\n",
       "      <td>-0.030714</td>\n",
       "      <td>-0.037103</td>\n",
       "      <td>-0.125494</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>0.058697</td>\n",
       "      <td>-0.071080</td>\n",
       "      <td>-0.045746</td>\n",
       "      <td>-0.031812</td>\n",
       "      <td>-0.051949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8957</th>\n",
       "      <td>0.432508</td>\n",
       "      <td>-1.036503</td>\n",
       "      <td>-0.323032</td>\n",
       "      <td>-0.313555</td>\n",
       "      <td>-0.095489</td>\n",
       "      <td>-0.065540</td>\n",
       "      <td>-0.001846</td>\n",
       "      <td>0.072808</td>\n",
       "      <td>-0.236015</td>\n",
       "      <td>0.025326</td>\n",
       "      <td>-0.304665</td>\n",
       "      <td>0.119372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8958</th>\n",
       "      <td>-0.469315</td>\n",
       "      <td>-0.103118</td>\n",
       "      <td>-0.166731</td>\n",
       "      <td>0.020001</td>\n",
       "      <td>-0.001781</td>\n",
       "      <td>-0.092196</td>\n",
       "      <td>-0.021631</td>\n",
       "      <td>0.064258</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.083946</td>\n",
       "      <td>-0.051404</td>\n",
       "      <td>-0.097235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>-0.454150</td>\n",
       "      <td>-0.109907</td>\n",
       "      <td>-0.203562</td>\n",
       "      <td>-0.048218</td>\n",
       "      <td>-0.032027</td>\n",
       "      <td>-0.114894</td>\n",
       "      <td>-0.023943</td>\n",
       "      <td>0.052404</td>\n",
       "      <td>-0.062311</td>\n",
       "      <td>-0.037609</td>\n",
       "      <td>-0.023811</td>\n",
       "      <td>-0.047803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>-0.569096</td>\n",
       "      <td>-1.155240</td>\n",
       "      <td>-0.452225</td>\n",
       "      <td>-0.433801</td>\n",
       "      <td>0.127891</td>\n",
       "      <td>0.310966</td>\n",
       "      <td>0.086382</td>\n",
       "      <td>-0.679785</td>\n",
       "      <td>0.151870</td>\n",
       "      <td>-0.549637</td>\n",
       "      <td>0.615062</td>\n",
       "      <td>0.947328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8961</th>\n",
       "      <td>0.851722</td>\n",
       "      <td>-1.439288</td>\n",
       "      <td>-0.459567</td>\n",
       "      <td>-0.524441</td>\n",
       "      <td>-0.132287</td>\n",
       "      <td>0.011133</td>\n",
       "      <td>-0.001661</td>\n",
       "      <td>0.107149</td>\n",
       "      <td>-0.315589</td>\n",
       "      <td>0.047712</td>\n",
       "      <td>-0.465397</td>\n",
       "      <td>0.161470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8962</th>\n",
       "      <td>-1.167586</td>\n",
       "      <td>-1.081925</td>\n",
       "      <td>-1.315938</td>\n",
       "      <td>-1.422433</td>\n",
       "      <td>-0.445764</td>\n",
       "      <td>-0.088532</td>\n",
       "      <td>0.041156</td>\n",
       "      <td>-0.058176</td>\n",
       "      <td>0.182561</td>\n",
       "      <td>-0.106113</td>\n",
       "      <td>0.712001</td>\n",
       "      <td>0.264944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8963</th>\n",
       "      <td>-0.488193</td>\n",
       "      <td>-0.095642</td>\n",
       "      <td>-0.170684</td>\n",
       "      <td>-0.005285</td>\n",
       "      <td>-0.001923</td>\n",
       "      <td>-0.097113</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>0.082432</td>\n",
       "      <td>-0.037475</td>\n",
       "      <td>-0.120906</td>\n",
       "      <td>-0.134216</td>\n",
       "      <td>-0.126211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8964</th>\n",
       "      <td>-0.417775</td>\n",
       "      <td>-0.071340</td>\n",
       "      <td>-0.143154</td>\n",
       "      <td>0.033547</td>\n",
       "      <td>-0.014581</td>\n",
       "      <td>-0.149825</td>\n",
       "      <td>-0.038769</td>\n",
       "      <td>0.067281</td>\n",
       "      <td>-0.076953</td>\n",
       "      <td>-0.021869</td>\n",
       "      <td>-0.078954</td>\n",
       "      <td>-0.096788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8965</th>\n",
       "      <td>-0.473903</td>\n",
       "      <td>-0.115277</td>\n",
       "      <td>-0.055158</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>0.148308</td>\n",
       "      <td>-0.230162</td>\n",
       "      <td>-0.029904</td>\n",
       "      <td>-0.001484</td>\n",
       "      <td>-0.130845</td>\n",
       "      <td>0.079085</td>\n",
       "      <td>-0.298467</td>\n",
       "      <td>-0.206546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8966</th>\n",
       "      <td>-0.439281</td>\n",
       "      <td>-0.126517</td>\n",
       "      <td>-0.199190</td>\n",
       "      <td>-0.048449</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.137921</td>\n",
       "      <td>-0.022887</td>\n",
       "      <td>0.060518</td>\n",
       "      <td>-0.073151</td>\n",
       "      <td>-0.030212</td>\n",
       "      <td>-0.060921</td>\n",
       "      <td>-0.068968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>-0.541332</td>\n",
       "      <td>-0.011053</td>\n",
       "      <td>-0.242643</td>\n",
       "      <td>-0.125596</td>\n",
       "      <td>-0.013470</td>\n",
       "      <td>-0.088397</td>\n",
       "      <td>-0.003722</td>\n",
       "      <td>0.124668</td>\n",
       "      <td>-0.038636</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>-0.067466</td>\n",
       "      <td>-0.032692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8968</th>\n",
       "      <td>-0.521916</td>\n",
       "      <td>-0.079734</td>\n",
       "      <td>-0.267106</td>\n",
       "      <td>-0.041044</td>\n",
       "      <td>-0.080093</td>\n",
       "      <td>-0.140789</td>\n",
       "      <td>-0.058272</td>\n",
       "      <td>0.133272</td>\n",
       "      <td>-0.114101</td>\n",
       "      <td>0.016790</td>\n",
       "      <td>0.103762</td>\n",
       "      <td>-0.167093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8969</th>\n",
       "      <td>-0.432934</td>\n",
       "      <td>-0.099384</td>\n",
       "      <td>-0.176815</td>\n",
       "      <td>-0.014411</td>\n",
       "      <td>-0.013073</td>\n",
       "      <td>-0.141200</td>\n",
       "      <td>-0.031682</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>-0.077213</td>\n",
       "      <td>-0.025177</td>\n",
       "      <td>-0.078550</td>\n",
       "      <td>-0.080533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8970</th>\n",
       "      <td>-0.453556</td>\n",
       "      <td>-0.131148</td>\n",
       "      <td>-0.207851</td>\n",
       "      <td>-0.057237</td>\n",
       "      <td>-0.023095</td>\n",
       "      <td>-0.112701</td>\n",
       "      <td>-0.018450</td>\n",
       "      <td>0.057731</td>\n",
       "      <td>-0.068064</td>\n",
       "      <td>-0.040323</td>\n",
       "      <td>-0.046748</td>\n",
       "      <td>-0.044867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>-0.448418</td>\n",
       "      <td>-0.098578</td>\n",
       "      <td>-0.194340</td>\n",
       "      <td>-0.039219</td>\n",
       "      <td>-0.027788</td>\n",
       "      <td>-0.135520</td>\n",
       "      <td>-0.026422</td>\n",
       "      <td>0.054950</td>\n",
       "      <td>-0.071136</td>\n",
       "      <td>-0.036196</td>\n",
       "      <td>-0.055453</td>\n",
       "      <td>-0.063835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8972</th>\n",
       "      <td>-0.442272</td>\n",
       "      <td>-0.090809</td>\n",
       "      <td>-0.198696</td>\n",
       "      <td>-0.036863</td>\n",
       "      <td>-0.034840</td>\n",
       "      <td>-0.123867</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>0.062259</td>\n",
       "      <td>-0.067246</td>\n",
       "      <td>-0.042940</td>\n",
       "      <td>-0.037987</td>\n",
       "      <td>-0.052853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>-0.446681</td>\n",
       "      <td>-0.101293</td>\n",
       "      <td>-0.199622</td>\n",
       "      <td>-0.036541</td>\n",
       "      <td>-0.038034</td>\n",
       "      <td>-0.118341</td>\n",
       "      <td>-0.024213</td>\n",
       "      <td>0.061597</td>\n",
       "      <td>-0.070792</td>\n",
       "      <td>-0.037482</td>\n",
       "      <td>-0.027560</td>\n",
       "      <td>-0.046664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>-0.395348</td>\n",
       "      <td>-0.072144</td>\n",
       "      <td>-0.194224</td>\n",
       "      <td>-0.027143</td>\n",
       "      <td>-0.010490</td>\n",
       "      <td>-0.120132</td>\n",
       "      <td>-0.020887</td>\n",
       "      <td>0.027012</td>\n",
       "      <td>-0.075468</td>\n",
       "      <td>-0.047163</td>\n",
       "      <td>-0.067957</td>\n",
       "      <td>-0.048682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8975</th>\n",
       "      <td>-0.462770</td>\n",
       "      <td>-0.201932</td>\n",
       "      <td>-0.228499</td>\n",
       "      <td>-0.083723</td>\n",
       "      <td>-0.022608</td>\n",
       "      <td>-0.070678</td>\n",
       "      <td>-0.006102</td>\n",
       "      <td>-0.014500</td>\n",
       "      <td>-0.054143</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.049829</td>\n",
       "      <td>0.039339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>-0.567748</td>\n",
       "      <td>-1.138324</td>\n",
       "      <td>-0.448409</td>\n",
       "      <td>-0.427881</td>\n",
       "      <td>0.124956</td>\n",
       "      <td>0.303791</td>\n",
       "      <td>0.084611</td>\n",
       "      <td>-0.667861</td>\n",
       "      <td>0.148400</td>\n",
       "      <td>-0.541279</td>\n",
       "      <td>0.604088</td>\n",
       "      <td>0.931212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8977</th>\n",
       "      <td>-0.453463</td>\n",
       "      <td>-0.100730</td>\n",
       "      <td>-0.198579</td>\n",
       "      <td>-0.042832</td>\n",
       "      <td>-0.029969</td>\n",
       "      <td>-0.123181</td>\n",
       "      <td>-0.029837</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>-0.057943</td>\n",
       "      <td>-0.041941</td>\n",
       "      <td>-0.040108</td>\n",
       "      <td>-0.055751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8978</th>\n",
       "      <td>-0.411037</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>-0.186030</td>\n",
       "      <td>-0.046188</td>\n",
       "      <td>-0.021268</td>\n",
       "      <td>-0.141735</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.052625</td>\n",
       "      <td>-0.071111</td>\n",
       "      <td>-0.007409</td>\n",
       "      <td>-0.037814</td>\n",
       "      <td>-0.052996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8979</th>\n",
       "      <td>-0.426983</td>\n",
       "      <td>-0.238625</td>\n",
       "      <td>-0.395347</td>\n",
       "      <td>-0.298627</td>\n",
       "      <td>-0.012577</td>\n",
       "      <td>-0.010213</td>\n",
       "      <td>0.012036</td>\n",
       "      <td>0.157212</td>\n",
       "      <td>-0.064725</td>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-0.170490</td>\n",
       "      <td>-0.184128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8980</th>\n",
       "      <td>-0.448676</td>\n",
       "      <td>-0.107484</td>\n",
       "      <td>-0.115723</td>\n",
       "      <td>-0.017287</td>\n",
       "      <td>0.089731</td>\n",
       "      <td>-0.195728</td>\n",
       "      <td>-0.023051</td>\n",
       "      <td>0.008345</td>\n",
       "      <td>-0.112332</td>\n",
       "      <td>0.035243</td>\n",
       "      <td>-0.209625</td>\n",
       "      <td>-0.161801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>-0.552942</td>\n",
       "      <td>-0.024576</td>\n",
       "      <td>-0.295169</td>\n",
       "      <td>-0.170420</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>-0.086287</td>\n",
       "      <td>-0.023418</td>\n",
       "      <td>0.137090</td>\n",
       "      <td>-0.029663</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>-0.101947</td>\n",
       "      <td>-0.058461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8982</th>\n",
       "      <td>-0.558620</td>\n",
       "      <td>-0.232029</td>\n",
       "      <td>-0.335865</td>\n",
       "      <td>-0.216729</td>\n",
       "      <td>-0.090833</td>\n",
       "      <td>-0.119096</td>\n",
       "      <td>-0.014170</td>\n",
       "      <td>0.030501</td>\n",
       "      <td>-0.032644</td>\n",
       "      <td>-0.050952</td>\n",
       "      <td>0.031057</td>\n",
       "      <td>0.003880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>-0.445488</td>\n",
       "      <td>-0.103774</td>\n",
       "      <td>-0.198765</td>\n",
       "      <td>-0.045332</td>\n",
       "      <td>-0.025189</td>\n",
       "      <td>-0.136606</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>0.059283</td>\n",
       "      <td>-0.072608</td>\n",
       "      <td>-0.034717</td>\n",
       "      <td>-0.061240</td>\n",
       "      <td>-0.068649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8984 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.487073 -0.051941 -0.226603  0.030900 -0.063577 -0.162661 -0.017905   \n",
       "1    -0.434773 -0.108206 -0.171983 -0.014569 -0.022807 -0.117358 -0.033876   \n",
       "2    -0.544055 -0.127321 -0.037105 -0.011069 -0.019062 -0.163652  0.001262   \n",
       "3    -0.450140 -0.092354 -0.195130 -0.034493 -0.029056 -0.134201 -0.025297   \n",
       "4    -0.458699 -0.124827 -0.194629 -0.056906 -0.030797 -0.132090 -0.023153   \n",
       "5    -0.421983 -0.120357 -0.150614 -0.004024 -0.052325 -0.163532 -0.032898   \n",
       "6    -0.447534 -0.093804 -0.196127 -0.034062 -0.028381 -0.134453 -0.025008   \n",
       "7    -0.432711 -0.225681 -0.245809 -0.149862  0.146671 -0.184242  0.059189   \n",
       "8    -0.449107 -0.092643 -0.194175 -0.032704 -0.027953 -0.135772 -0.025124   \n",
       "9    -0.448208 -0.089543 -0.197800 -0.039661 -0.024924 -0.127768 -0.022250   \n",
       "10   -0.430242 -0.075315 -0.209216 -0.027813 -0.068596 -0.147854 -0.013622   \n",
       "11   -0.446312 -0.095049 -0.201188 -0.051528 -0.021639 -0.125202 -0.023030   \n",
       "12   -0.450978 -0.089782 -0.194445 -0.031627 -0.035094 -0.135418 -0.024901   \n",
       "13   -0.437524 -0.088886 -0.193748 -0.023335 -0.034550 -0.130217 -0.019575   \n",
       "14   -0.451556 -0.093439 -0.194274 -0.029520 -0.031494 -0.132821 -0.028284   \n",
       "15   -0.435645 -0.083009 -0.179448 -0.001287 -0.100296 -0.119823 -0.038325   \n",
       "16   -0.456952 -0.087991 -0.193980 -0.036015 -0.015544 -0.153149 -0.015548   \n",
       "17   -0.409110 -0.051906 -0.176623 -0.061109  0.021533 -0.130983 -0.022154   \n",
       "18   -0.434199 -0.070968 -0.204979 -0.032721 -0.030834 -0.123683 -0.031822   \n",
       "19   -0.449022 -0.090964 -0.195310 -0.036628 -0.030363 -0.133057 -0.024102   \n",
       "20   -0.445413 -0.093948 -0.203051 -0.046387 -0.028624 -0.135837 -0.027339   \n",
       "21   -0.441093 -0.100389 -0.173868 -0.032396 -0.033083 -0.136425 -0.027751   \n",
       "22   -0.467689 -0.098142 -0.201736 -0.034719 -0.035446 -0.138558 -0.027961   \n",
       "23   -0.456351 -0.091754 -0.196007 -0.020438 -0.025942 -0.140279 -0.028564   \n",
       "24   -0.450880 -0.091752 -0.195809 -0.031141 -0.029450 -0.132585 -0.026289   \n",
       "25   -0.455445 -0.101219 -0.191390 -0.042151 -0.026747 -0.124375 -0.026208   \n",
       "26   -0.444880 -0.093161 -0.202010 -0.036463 -0.031884 -0.137586 -0.025706   \n",
       "27   -0.449716 -0.095940 -0.189984 -0.033632 -0.028682 -0.137063 -0.026840   \n",
       "28   -0.457471 -0.090431 -0.195849 -0.028560 -0.028550 -0.133081 -0.025887   \n",
       "29   -0.457824 -0.087208 -0.205804 -0.021847 -0.045481 -0.139487 -0.027282   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8954 -0.415932 -0.047950 -0.237582 -0.047505 -0.025621 -0.128447 -0.014428   \n",
       "8955 -0.470480 -0.110122 -0.203515 -0.049298 -0.029405 -0.113909 -0.027469   \n",
       "8956 -0.449167 -0.091521 -0.190214 -0.030714 -0.037103 -0.125494 -0.027380   \n",
       "8957  0.432508 -1.036503 -0.323032 -0.313555 -0.095489 -0.065540 -0.001846   \n",
       "8958 -0.469315 -0.103118 -0.166731  0.020001 -0.001781 -0.092196 -0.021631   \n",
       "8959 -0.454150 -0.109907 -0.203562 -0.048218 -0.032027 -0.114894 -0.023943   \n",
       "8960 -0.569096 -1.155240 -0.452225 -0.433801  0.127891  0.310966  0.086382   \n",
       "8961  0.851722 -1.439288 -0.459567 -0.524441 -0.132287  0.011133 -0.001661   \n",
       "8962 -1.167586 -1.081925 -1.315938 -1.422433 -0.445764 -0.088532  0.041156   \n",
       "8963 -0.488193 -0.095642 -0.170684 -0.005285 -0.001923 -0.097113  0.009890   \n",
       "8964 -0.417775 -0.071340 -0.143154  0.033547 -0.014581 -0.149825 -0.038769   \n",
       "8965 -0.473903 -0.115277 -0.055158  0.018052  0.148308 -0.230162 -0.029904   \n",
       "8966 -0.439281 -0.126517 -0.199190 -0.048449 -0.023374 -0.137921 -0.022887   \n",
       "8967 -0.541332 -0.011053 -0.242643 -0.125596 -0.013470 -0.088397 -0.003722   \n",
       "8968 -0.521916 -0.079734 -0.267106 -0.041044 -0.080093 -0.140789 -0.058272   \n",
       "8969 -0.432934 -0.099384 -0.176815 -0.014411 -0.013073 -0.141200 -0.031682   \n",
       "8970 -0.453556 -0.131148 -0.207851 -0.057237 -0.023095 -0.112701 -0.018450   \n",
       "8971 -0.448418 -0.098578 -0.194340 -0.039219 -0.027788 -0.135520 -0.026422   \n",
       "8972 -0.442272 -0.090809 -0.198696 -0.036863 -0.034840 -0.123867 -0.026820   \n",
       "8973 -0.446681 -0.101293 -0.199622 -0.036541 -0.038034 -0.118341 -0.024213   \n",
       "8974 -0.395348 -0.072144 -0.194224 -0.027143 -0.010490 -0.120132 -0.020887   \n",
       "8975 -0.462770 -0.201932 -0.228499 -0.083723 -0.022608 -0.070678 -0.006102   \n",
       "8976 -0.567748 -1.138324 -0.448409 -0.427881  0.124956  0.303791  0.084611   \n",
       "8977 -0.453463 -0.100730 -0.198579 -0.042832 -0.029969 -0.123181 -0.029837   \n",
       "8978 -0.411037 -0.251471 -0.186030 -0.046188 -0.021268 -0.141735  0.004838   \n",
       "8979 -0.426983 -0.238625 -0.395347 -0.298627 -0.012577 -0.010213  0.012036   \n",
       "8980 -0.448676 -0.107484 -0.115723 -0.017287  0.089731 -0.195728 -0.023051   \n",
       "8981 -0.552942 -0.024576 -0.295169 -0.170420 -0.031563 -0.086287 -0.023418   \n",
       "8982 -0.558620 -0.232029 -0.335865 -0.216729 -0.090833 -0.119096 -0.014170   \n",
       "8983 -0.445488 -0.103774 -0.198765 -0.045332 -0.025189 -0.136606 -0.026956   \n",
       "\n",
       "            7         8         9         10        11  \n",
       "0     0.000993 -0.151535 -0.033055 -0.041524 -0.021534  \n",
       "1     0.016708 -0.085069 -0.033533 -0.026774 -0.025030  \n",
       "2     0.056846 -0.335119  0.015169 -0.051240 -0.170916  \n",
       "3     0.049022 -0.065971 -0.043972 -0.033158 -0.050865  \n",
       "4     0.062247 -0.075484 -0.036713 -0.041619 -0.058612  \n",
       "5     0.019747 -0.025566 -0.063220 -0.047534 -0.047100  \n",
       "6     0.047535 -0.066097 -0.044318 -0.039291 -0.050376  \n",
       "7    -0.238936 -0.198903 -0.023234 -0.097759 -0.114590  \n",
       "8     0.045289 -0.065096 -0.045620 -0.036024 -0.051876  \n",
       "9     0.052804 -0.065404 -0.044915 -0.032151 -0.047482  \n",
       "10    0.027992 -0.103338 -0.063127 -0.023186 -0.093005  \n",
       "11    0.059002 -0.053140 -0.046426 -0.042267 -0.054365  \n",
       "12    0.048489 -0.061373 -0.043849 -0.039482 -0.050916  \n",
       "13    0.053279 -0.062043 -0.050505 -0.040475 -0.061962  \n",
       "14    0.049554 -0.064664 -0.045983 -0.035613 -0.048866  \n",
       "15    0.063732 -0.054125 -0.069522 -0.037454 -0.009828  \n",
       "16    0.032429 -0.069187 -0.045244 -0.046574 -0.054838  \n",
       "17    0.065370 -0.077570 -0.070060  0.038750  0.041271  \n",
       "18    0.066020 -0.100836 -0.052413 -0.007335 -0.051503  \n",
       "19    0.048363 -0.065886 -0.044525 -0.032357 -0.053167  \n",
       "20    0.042864 -0.064514 -0.057108 -0.023180 -0.046332  \n",
       "21    0.047227 -0.064341 -0.047166 -0.046484 -0.049361  \n",
       "22    0.061778 -0.053089 -0.045465 -0.058738 -0.037991  \n",
       "23    0.033255 -0.073736 -0.046194 -0.021626 -0.051936  \n",
       "24    0.050039 -0.066617 -0.045034 -0.035011 -0.049542  \n",
       "25    0.077008 -0.092376 -0.034731 -0.033314 -0.062440  \n",
       "26    0.040555 -0.066295 -0.046283 -0.039678 -0.050122  \n",
       "27    0.047700 -0.065218 -0.045327 -0.042675 -0.049274  \n",
       "28    0.048251 -0.062629 -0.047452 -0.032857 -0.049906  \n",
       "29    0.037900 -0.086021 -0.039618 -0.043973 -0.044833  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "8954  0.016240 -0.058660 -0.049415 -0.015131 -0.057539  \n",
       "8955  0.078375 -0.058277 -0.037773 -0.057521 -0.062583  \n",
       "8956  0.058697 -0.071080 -0.045746 -0.031812 -0.051949  \n",
       "8957  0.072808 -0.236015  0.025326 -0.304665  0.119372  \n",
       "8958  0.064258 -0.050624 -0.083946 -0.051404 -0.097235  \n",
       "8959  0.052404 -0.062311 -0.037609 -0.023811 -0.047803  \n",
       "8960 -0.679785  0.151870 -0.549637  0.615062  0.947328  \n",
       "8961  0.107149 -0.315589  0.047712 -0.465397  0.161470  \n",
       "8962 -0.058176  0.182561 -0.106113  0.712001  0.264944  \n",
       "8963  0.082432 -0.037475 -0.120906 -0.134216 -0.126211  \n",
       "8964  0.067281 -0.076953 -0.021869 -0.078954 -0.096788  \n",
       "8965 -0.001484 -0.130845  0.079085 -0.298467 -0.206546  \n",
       "8966  0.060518 -0.073151 -0.030212 -0.060921 -0.068968  \n",
       "8967  0.124668 -0.038636  0.002284 -0.067466 -0.032692  \n",
       "8968  0.133272 -0.114101  0.016790  0.103762 -0.167093  \n",
       "8969  0.053727 -0.077213 -0.025177 -0.078550 -0.080533  \n",
       "8970  0.057731 -0.068064 -0.040323 -0.046748 -0.044867  \n",
       "8971  0.054950 -0.071136 -0.036196 -0.055453 -0.063835  \n",
       "8972  0.062259 -0.067246 -0.042940 -0.037987 -0.052853  \n",
       "8973  0.061597 -0.070792 -0.037482 -0.027560 -0.046664  \n",
       "8974  0.027012 -0.075468 -0.047163 -0.067957 -0.048682  \n",
       "8975 -0.014500 -0.054143 -0.069270  0.049829  0.039339  \n",
       "8976 -0.667861  0.148400 -0.541279  0.604088  0.931212  \n",
       "8977  0.059166 -0.057943 -0.041941 -0.040108 -0.055751  \n",
       "8978  0.052625 -0.071111 -0.007409 -0.037814 -0.052996  \n",
       "8979  0.157212 -0.064725 -0.007558 -0.170490 -0.184128  \n",
       "8980  0.008345 -0.112332  0.035243 -0.209625 -0.161801  \n",
       "8981  0.137090 -0.029663  0.005298 -0.101947 -0.058461  \n",
       "8982  0.030501 -0.032644 -0.050952  0.031057  0.003880  \n",
       "8983  0.059283 -0.072608 -0.034717 -0.061240 -0.068649  \n",
       "\n",
       "[8984 rows x 12 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Neural Network model implementation using keras and tensorflow #############\n",
    "#!pip install tensorflow\n",
    "#!pip install keras\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "model=Sequential()\n",
    "#adding input layer\n",
    "model.add(Dense(12,activation='relu',input_shape=(12,)))\n",
    "#adding hidden layer\n",
    "model.add(Dense(8,activation='relu'))\n",
    "#adding output layer\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5097</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label\n",
       "3948     0\n",
       "5097     0\n",
       "3689     0\n",
       "1499     0\n",
       "5217     0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.output_shape\n",
    "# model.summary()\n",
    "# model.get_config()\n",
    "# model.get_weights()\n",
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8984/8984 [==============================] - 8s 848us/step - loss: 0.4145 - acc: 0.8363\n",
      "Epoch 2/3\n",
      "8984/8984 [==============================] - 8s 837us/step - loss: 0.3780 - acc: 0.8515\n",
      "Epoch 3/3\n",
      "8984/8984 [==============================] - 8s 877us/step - loss: 0.3481 - acc: 0.8652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1aa99d4bef0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=3,batch_size=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132/1132 [==============================] - 0s 29us/step\n",
      "[0.461072527056448, 0.823321554770318]\n"
     ]
    }
   ],
   "source": [
    "score=model.evaluate(X_test,y_test,verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-d36ee26f3614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcohen_kappa_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0munique_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munion1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munion1d\u001b[1;34m(ar1, ar2)\u001b[0m\n\u001b[0;32m    736\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m     \"\"\"\n\u001b[1;32m--> 738\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mar2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
